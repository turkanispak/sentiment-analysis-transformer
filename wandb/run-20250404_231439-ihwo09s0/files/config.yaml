_wandb:
    value:
        cli_version: 0.19.8
        m: []
        python_version: 3.12.7
        t:
            "1":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 53
                - 55
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 53
                - 55
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.12.7
            "5": 0.19.8
            "6": 4.50.3
            "8":
                - 3
                - 5
            "12": 0.19.8
            "13": windows-amd64
always_save_checkpoint:
    value: false
backend:
    value: nccl
batch_size:
    value: 1
beta1:
    value: 0.9
beta2:
    value: 0.95
bias:
    value: false
block_size:
    value: 1024
compile:
    value: false
dataset:
    value: data_gpt2
decay_lr:
    value: false
device:
    value: cuda
dropout:
    value: 0
dtype:
    value: bfloat16
eval_interval:
    value: 5
eval_iters:
    value: 40
eval_only:
    value: false
grad_clip:
    value: 1
gradient_accumulation_steps:
    value: 32
init_from:
    value: gpt2
learning_rate:
    value: 3e-05
log_interval:
    value: 1
lr_decay_iters:
    value: 600000
max_iters:
    value: 200
min_lr:
    value: 6e-05
n_embd:
    value: 768
n_head:
    value: 12
n_layer:
    value: 12
out_dir:
    value: out-gpt2-finetune
wandb_log:
    value: true
wandb_project:
    value: transformer-sentiment-analysis
wandb_run_name:
    value: ft-gpt2-customer-1743797670.2400203
warmup_iters:
    value: 2000
weight_decay:
    value: 0.1
